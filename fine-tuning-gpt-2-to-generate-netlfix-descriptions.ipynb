{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2654038,"sourceType":"datasetVersion","datasetId":434238}],"dockerImageVersionId":30086,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pip install git+https://github.com/huggingface/transformers@master","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:52:23.326381Z","iopub.execute_input":"2024-02-16T15:52:23.326669Z","iopub.status.idle":"2024-02-16T15:52:40.863887Z","shell.execute_reply.started":"2024-02-16T15:52:23.326639Z","shell.execute_reply":"2024-02-16T15:52:40.862855Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers@master\n  Cloning https://github.com/huggingface/transformers (to revision master) to /tmp/pip-req-build-rz0p8alx\n  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-rz0p8alx\n\u001b[33m  WARNING: Did not find branch or tag 'master', assuming revision or ref.\u001b[0m\n  Running command git checkout -q master\n  error: pathspec 'master' did not match any file(s) known to git.\n\u001b[33mWARNING: Discarding git+https://github.com/huggingface/transformers@master. Command errored out with exit status 1: git checkout -q master Check the logs for full command output.\u001b[0m\n\u001b[31mERROR: Command errored out with exit status 1: git checkout -q master Check the logs for full command output.\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-16T15:52:40.865931Z","iopub.execute_input":"2024-02-16T15:52:40.866222Z","iopub.status.idle":"2024-02-16T15:52:48.259683Z","shell.execute_reply.started":"2024-02-16T15:52:40.866192Z","shell.execute_reply":"2024-02-16T15:52:48.258947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:52:48.260825Z","iopub.execute_input":"2024-02-16T15:52:48.261079Z","iopub.status.idle":"2024-02-16T15:52:49.260003Z","shell.execute_reply.started":"2024-02-16T15:52:48.261054Z","shell.execute_reply":"2024-02-16T15:52:49.259044Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Fri Feb 16 15:52:49 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0              26W / 250W |      0MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:52:49.261520Z","iopub.execute_input":"2024-02-16T15:52:49.261838Z","iopub.status.idle":"2024-02-16T15:52:49.273432Z","shell.execute_reply.started":"2024-02-16T15:52:49.261806Z","shell.execute_reply":"2024-02-16T15:52:49.272584Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7b974c154490>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loading GPT2-Medium Model from ðŸ¤— Model Hub ","metadata":{}},{"cell_type":"code","source":"\n\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', bos_token='<|startoftext|>',\n                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium').cuda()\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:52:49.276916Z","iopub.execute_input":"2024-02-16T15:52:49.277189Z","iopub.status.idle":"2024-02-16T15:53:46.716043Z","shell.execute_reply.started":"2024-02-16T15:52:49.277162Z","shell.execute_reply":"2024-02-16T15:53:46.715204Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6843760a64f4ba895101e269051ae83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b22e61598f04aeca574c10db1492058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d628b6bf931743c59e5fd8290c81d90b"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fcf9226a2014511af54ebe314aa6803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f8c18c379f42e9be0eaec5c775c361"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 1024)"},"metadata":{}}]},{"cell_type":"code","source":"descriptions = pd.read_csv('../input/netflix-shows/netflix_titles.csv')['description']","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:46.717401Z","iopub.execute_input":"2024-02-16T15:53:46.717668Z","iopub.status.idle":"2024-02-16T15:53:46.822426Z","shell.execute_reply.started":"2024-02-16T15:53:46.717642Z","shell.execute_reply":"2024-02-16T15:53:46.821752Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max_length = max([len(tokenizer.encode(description)) for description in descriptions])","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:46.823711Z","iopub.execute_input":"2024-02-16T15:53:46.824026Z","iopub.status.idle":"2024-02-16T15:53:50.706713Z","shell.execute_reply.started":"2024-02-16T15:53:46.823998Z","shell.execute_reply":"2024-02-16T15:53:50.706005Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class NetflixDataset(Dataset):\n    def __init__(self, txt_list, tokenizer, max_length):\n        self.input_ids = []\n        self.attn_masks = []\n        self.labels = []\n        for txt in txt_list:\n            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n                                       max_length=max_length, padding=\"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx]","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:50.707916Z","iopub.execute_input":"2024-02-16T15:53:50.708178Z","iopub.status.idle":"2024-02-16T15:53:50.715491Z","shell.execute_reply.started":"2024-02-16T15:53:50.708152Z","shell.execute_reply":"2024-02-16T15:53:50.714441Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = NetflixDataset(descriptions, tokenizer, max_length=max_length)\ntrain_size = int(0.9 * len(dataset))\ntrain_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:50.716675Z","iopub.execute_input":"2024-02-16T15:53:50.717073Z","iopub.status.idle":"2024-02-16T15:53:53.627776Z","shell.execute_reply.started":"2024-02-16T15:53:50.717045Z","shell.execute_reply":"2024-02-16T15:53:53.626927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:53.628987Z","iopub.execute_input":"2024-02-16T15:53:53.629255Z","iopub.status.idle":"2024-02-16T15:53:53.875533Z","shell.execute_reply.started":"2024-02-16T15:53:53.629229Z","shell.execute_reply":"2024-02-16T15:53:53.874499Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"669"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:53.877017Z","iopub.execute_input":"2024-02-16T15:53:53.877400Z","iopub.status.idle":"2024-02-16T15:53:53.886996Z","shell.execute_reply.started":"2024-02-16T15:53:53.877358Z","shell.execute_reply":"2024-02-16T15:53:53.886234Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='./results', num_train_epochs=1, logging_steps=100, save_steps=5000,\n                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:53.888388Z","iopub.execute_input":"2024-02-16T15:53:53.888670Z","iopub.status.idle":"2024-02-16T15:53:53.900677Z","shell.execute_reply.started":"2024-02-16T15:53:53.888643Z","shell.execute_reply":"2024-02-16T15:53:53.900065Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n                                                              'attention_mask': torch.stack([f[1] for f in data]),\n                                                              'labels': torch.stack([f[0] for f in data])}).train()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:53:53.901946Z","iopub.execute_input":"2024-02-16T15:53:53.902297Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='1191' max='7926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1191/7926 03:28 < 19:40, 5.71 it/s, Epoch 0.15/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>5.836100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.961300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.895700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.951800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.943900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.807000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.854600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.917300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.872200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.778300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.799700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"### GPT Generated Description","metadata":{}},{"cell_type":"code","source":"generated = tokenizer(\"<|startoftext|> \", return_tensors=\"pt\").input_ids.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_outputs = model.generate(generated, do_sample=True, top_k=50, \n                                max_length=300, top_p=0.95, temperature=1.9, num_return_sequences=20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original Description (Random)","metadata":{}},{"cell_type":"code","source":"pd.options.display.max_colwidth = 1000\ndescriptions.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
