{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30214,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srinivasulu2003/DeepLearning/blob/main/finetune_bloom_token_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning BLOOM for Token Classification\n",
        "\n",
        "\n",
        "**Information about BLOOM:**\n",
        "\n",
        "* Documentation: https://huggingface.co/docs/transformers/model_doc/bloom\n",
        "* Model: https://huggingface.co/bigscience/bloom\n",
        "* Github: https://github.com/bigscience-workshop/bigscience/tree/master/train/tr11-176B-ml#readme\n",
        "\n",
        "**Transformers Package Documentation in Huggingface.co:**\n",
        "\n",
        "* Tokenizer Class: https://huggingface.co/docs/transformers/glossary#attention-mask\n",
        "* Trainer Class: https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.Trainer\n",
        "* Finetuning using Trainer: https://huggingface.co/docs/transformers/training\n",
        "* Token Classification: https://huggingface.co/docs/transformers/tasks/token_classification\n",
        "\n",
        "**Architecture explained:**\n",
        "\n",
        "* The Technology Behind BLOOM Training: https://huggingface.co/blog/bloom-megatron-deepspeed\n",
        "* Understand BLOOM, the Largest Open-Access AI, and Run It on Your Local Computer:\n",
        "    https://towardsdatascience.com/run-bloom-the-largest-open-access-ai-model-on-your-desktop-computer-f48e1e2a9a32\n",
        "\n",
        "**Dataset used for Training explained:**\n",
        "\n",
        "* Corpus Map: https://huggingface.co/spaces/bigscience-catalogue-lm-data/corpus-map\n",
        "* Building a TB Scale Multilingual Dataset for Language Modeling: https://bigscience.huggingface.co/blog/building-a-tb-scale-multilingual-dataset-for-language-modeling\n",
        "\n",
        "\n",
        "**Dataset for Finetuning:**\n",
        "\n",
        "* Conll2003: https://huggingface.co/datasets/conll2003"
      ],
      "metadata": {
        "id": "-PcYka1Buzv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About BLOOM:\n",
        "\n",
        "**The Model**:\n",
        "* 176B parameters decoder-only architecture (GPT-like)\n",
        "* 70 layers - 112 attention heads per layers - hidden dimensionality of 14336 - 2048 tokens sequence length\n",
        "    \n",
        "    \n",
        "BLOOM uses a Transformer architecture composed of an input embeddings layer, 70 Transformer blocks, and an output language-modeling layer, as shown in the figure below. Each Transformer block has a self-attention layer and a multi-layer perceptron layer, with input and post-attention layer norms.\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*uwWJBgEx3Rtovbcb7HcRdA.jpeg)\n",
        "    \n",
        "**The Dataset**:\n",
        "* Multilingual: 46 languages: Full list is here: [https://bigscience.huggingface.co/blog/building-a-tb-scale-multilingual-dataset-for-language-modeling](https://bigscience.huggingface.co/blog/building-a-tb-scale-multilingual-dataset-for-language-modeling)\n",
        "* 341.6 billion tokens (1.5 TB of text data)\n",
        "* Tokenizer vocabulary: 250 680 tokens\n",
        "\n",
        "![](https://github.com/bigscience-workshop/model_card/blob/main/assets/data/pie_v2.svg?raw=true)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-09T23:33:56.815995Z",
          "iopub.execute_input": "2022-08-09T23:33:56.817108Z",
          "iopub.status.idle": "2022-08-09T23:33:56.822165Z",
          "shell.execute_reply.started": "2022-08-09T23:33:56.817071Z",
          "shell.execute_reply": "2022-08-09T23:33:56.820886Z"
        },
        "id": "Qd6lC-E1uzv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "mMpbNR3tuzv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "hDgWwy8Buzv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (BloomTokenizerFast,\n",
        "                          BloomForTokenClassification,\n",
        "                          DataCollatorForTokenClassification,\n",
        "                          AutoModelForTokenClassification,\n",
        "                          TrainingArguments, Trainer)\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "id": "jYGtYy-nuzv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Pretrained Model"
      ],
      "metadata": {
        "id": "WFQ6sBSVuzv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model ans Tokenizer:**\n",
        "\n",
        "The list of available Models can be found here: https://huggingface.co/docs/transformers/model_doc/bloom"
      ],
      "metadata": {
        "id": "uOSL-AURuzv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bloom-560m\"\n",
        "tokenizer = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)\n",
        "model = BloomForTokenClassification.from_pretrained(f\"bigscience/{model_name}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:06:00.61004Z",
          "iopub.execute_input": "2022-08-10T00:06:00.610779Z",
          "iopub.status.idle": "2022-08-10T00:07:52.837713Z",
          "shell.execute_reply.started": "2022-08-10T00:06:00.61074Z",
          "shell.execute_reply": "2022-08-10T00:07:52.836705Z"
        },
        "trusted": true,
        "id": "AVvh80TDuzv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:07:52.839395Z",
          "iopub.execute_input": "2022-08-10T00:07:52.839943Z",
          "iopub.status.idle": "2022-08-10T00:07:52.848963Z",
          "shell.execute_reply.started": "2022-08-10T00:07:52.839906Z",
          "shell.execute_reply": "2022-08-10T00:07:52.847946Z"
        },
        "trusted": true,
        "id": "566JX57-uzv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict Labels:**\n",
        "\n",
        "Since Bloom has not been fintuned for Token Classification yet, the prediction is poor as expected."
      ],
      "metadata": {
        "id": "q08QcL4Auzv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    \"HuggingFace is a company based in Paris and New York\", add_special_tokens=False, return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_token_class_ids = logits.argmax(-1)\n",
        "\n",
        "# Note that tokens are classified rather then input words which means that\n",
        "# there might be more predicted token classes than words.\n",
        "# Multiple token classes might account for the same word\n",
        "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
        "predicted_tokens_classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:07:52.851839Z",
          "iopub.execute_input": "2022-08-10T00:07:52.852545Z",
          "iopub.status.idle": "2022-08-10T00:07:53.307227Z",
          "shell.execute_reply.started": "2022-08-10T00:07:52.852509Z",
          "shell.execute_reply": "2022-08-10T00:07:53.306232Z"
        },
        "trusted": true,
        "id": "xaa-3iTwuzv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset for Finetuning"
      ],
      "metadata": {
        "id": "VvEzF59quzwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See:\n",
        "* Dataset on Huggingface: https://huggingface.co/datasets/conll2003\n",
        "* Load Datasets: https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/loading_methods"
      ],
      "metadata": {
        "id": "0vxRaHHKuzwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = load_dataset('conll2003')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:07:53.308691Z",
          "iopub.execute_input": "2022-08-10T00:07:53.309504Z",
          "iopub.status.idle": "2022-08-10T00:08:01.442816Z",
          "shell.execute_reply.started": "2022-08-10T00:07:53.309468Z",
          "shell.execute_reply": "2022-08-10T00:08:01.441929Z"
        },
        "trusted": true,
        "id": "nJINjVqeuzwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the Dataset:"
      ],
      "metadata": {
        "id": "sVt_askCuzwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Examples:**"
      ],
      "metadata": {
        "id": "rnKpxkdduzwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Object Type:\", type(datasets[\"train\"]))\n",
        "print(\"Training Examples:\", len(datasets[\"train\"]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.444384Z",
          "iopub.execute_input": "2022-08-10T00:08:01.444967Z",
          "iopub.status.idle": "2022-08-10T00:08:01.454279Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.444929Z",
          "shell.execute_reply": "2022-08-10T00:08:01.45334Z"
        },
        "trusted": true,
        "id": "bSMYihHCuzwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Structure:**"
      ],
      "metadata": {
        "id": "QC7VNImguzwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[\"train\"][100]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.455773Z",
          "iopub.execute_input": "2022-08-10T00:08:01.456393Z",
          "iopub.status.idle": "2022-08-10T00:08:01.475936Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.456356Z",
          "shell.execute_reply": "2022-08-10T00:08:01.474967Z"
        },
        "trusted": true,
        "id": "RO3ZqRYAuzwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Labels:**"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T16:13:00.916311Z",
          "iopub.execute_input": "2022-08-08T16:13:00.916799Z",
          "iopub.status.idle": "2022-08-08T16:13:00.924905Z",
          "shell.execute_reply.started": "2022-08-08T16:13:00.916763Z",
          "shell.execute_reply": "2022-08-08T16:13:00.922929Z"
        },
        "id": "MPZO3EjLuzwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
        "label_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.477717Z",
          "iopub.execute_input": "2022-08-10T00:08:01.478415Z",
          "iopub.status.idle": "2022-08-10T00:08:01.490386Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.478319Z",
          "shell.execute_reply": "2022-08-10T00:08:01.489348Z"
        },
        "trusted": true,
        "id": "_UOvgNEIuzwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize Dataset"
      ],
      "metadata": {
        "id": "xx0pkAv3uzwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize a Single Sample:"
      ],
      "metadata": {
        "id": "Ge29hTHGuzwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasets[\"train\"][0]\n",
        "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "print(tokens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.491866Z",
          "iopub.execute_input": "2022-08-10T00:08:01.492538Z",
          "iopub.status.idle": "2022-08-10T00:08:01.50898Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.492493Z",
          "shell.execute_reply": "2022-08-10T00:08:01.507273Z"
        },
        "trusted": true,
        "id": "MvFlx0DguzwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample after Tokenization:"
      ],
      "metadata": {
        "id": "pbI95D-HuzwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.514241Z",
          "iopub.execute_input": "2022-08-10T00:08:01.514922Z",
          "iopub.status.idle": "2022-08-10T00:08:01.525765Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.51488Z",
          "shell.execute_reply": "2022-08-10T00:08:01.524558Z"
        },
        "trusted": true,
        "id": "09QFwWM0uzwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word IDs:"
      ],
      "metadata": {
        "id": "sJlTO2ZkuzwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input.word_ids()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.527901Z",
          "iopub.execute_input": "2022-08-10T00:08:01.528365Z",
          "iopub.status.idle": "2022-08-10T00:08:01.537066Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.528329Z",
          "shell.execute_reply": "2022-08-10T00:08:01.536027Z"
        },
        "trusted": true,
        "id": "ri_8DTMLuzwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize Whole Dataset"
      ],
      "metadata": {
        "id": "Ej9rE77-uzwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizeInputs(inputs):\n",
        "\n",
        "    tokenized_inputs = tokenizer(inputs[\"tokens\"], max_length = 512, truncation=True, is_split_into_words=True)\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "    ner_tags = inputs[\"ner_tags\"]\n",
        "    labels = [ner_tags[word_id] for word_id in word_ids]\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.538589Z",
          "iopub.execute_input": "2022-08-10T00:08:01.539735Z",
          "iopub.status.idle": "2022-08-10T00:08:01.546791Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.539706Z",
          "shell.execute_reply": "2022-08-10T00:08:01.545718Z"
        },
        "trusted": true,
        "id": "w2SN0FoFuzwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasets[\"train\"][100]\n",
        "tokenizeInputs(example)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.548588Z",
          "iopub.execute_input": "2022-08-10T00:08:01.549046Z",
          "iopub.status.idle": "2022-08-10T00:08:01.561066Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.549009Z",
          "shell.execute_reply": "2022-08-10T00:08:01.559606Z"
        },
        "trusted": true,
        "id": "ZuWIiDRduzwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = datasets.map(tokenizeInputs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:01.562753Z",
          "iopub.execute_input": "2022-08-10T00:08:01.563552Z",
          "iopub.status.idle": "2022-08-10T00:08:09.753227Z",
          "shell.execute_reply.started": "2022-08-10T00:08:01.563514Z",
          "shell.execute_reply": "2022-08-10T00:08:09.752345Z"
        },
        "trusted": true,
        "id": "HYjk2lXbuzwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count of Tokens in the Training Set:**"
      ],
      "metadata": {
        "id": "bPG0k7JVuzwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_count = 0\n",
        "for sample in tokenized_datasets[\"train\"]:\n",
        "    token_count = token_count + len(sample[\"labels\"])\n",
        "\n",
        "print(\"Tokens in Training Set:\", token_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:09.756951Z",
          "iopub.execute_input": "2022-08-10T00:08:09.758559Z",
          "iopub.status.idle": "2022-08-10T00:08:12.18139Z",
          "shell.execute_reply.started": "2022-08-10T00:08:09.75852Z",
          "shell.execute_reply": "2022-08-10T00:08:12.180194Z"
        },
        "trusted": true,
        "id": "nexgB3f4uzwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"id\", \"tokens\", \"ner_tags\", \"pos_tags\", \"chunk_tags\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:12.18582Z",
          "iopub.execute_input": "2022-08-10T00:08:12.188076Z",
          "iopub.status.idle": "2022-08-10T00:08:12.204659Z",
          "shell.execute_reply.started": "2022-08-10T00:08:12.188037Z",
          "shell.execute_reply": "2022-08-10T00:08:12.203412Z"
        },
        "trusted": true,
        "id": "-7oStHm8uzwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Data Collator"
      ],
      "metadata": {
        "id": "QF7UUk7_uzwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:12.209696Z",
          "iopub.execute_input": "2022-08-10T00:08:12.211934Z",
          "iopub.status.idle": "2022-08-10T00:08:12.217931Z",
          "shell.execute_reply.started": "2022-08-10T00:08:12.211895Z",
          "shell.execute_reply": "2022-08-10T00:08:12.21679Z"
        },
        "trusted": true,
        "id": "5jCLOUXouzwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Trainer"
      ],
      "metadata": {
        "id": "Is0wvwQTuzwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model Class which can be finetuned:"
      ],
      "metadata": {
        "id": "_EdbIIT8uzwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(f\"bigscience/{model_name}\", num_labels=12).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:12.222716Z",
          "iopub.execute_input": "2022-08-10T00:08:12.225194Z",
          "iopub.status.idle": "2022-08-10T00:08:25.468406Z",
          "shell.execute_reply.started": "2022-08-10T00:08:12.225157Z",
          "shell.execute_reply": "2022-08-10T00:08:25.467355Z"
        },
        "trusted": true,
        "id": "0Ezynsh-uzwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About the Model:\n",
        "\n",
        "see https://github.com/huggingface/transformers/blob/v4.21.1/src/transformers/modeling_utils.py#L829"
      ],
      "metadata": {
        "id": "Je4dz--ZuzwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Parameters:\", model.num_parameters())\n",
        "print(\"Expected Input Dict:\", model.main_input_name )\n",
        "\n",
        "# Estimate FLOPS needed for one training example\n",
        "sample = tokenized_datasets[\"train\"][0]\n",
        "sample[\"input_ids\"] = torch.Tensor(sample[\"input_ids\"])\n",
        "flops_est = model.floating_point_ops(input_dict = sample, exclude_embeddings = False)\n",
        "\n",
        "print(\"FLOPS needed per Training Sample:\", flops_est )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:25.470134Z",
          "iopub.execute_input": "2022-08-10T00:08:25.470551Z",
          "iopub.status.idle": "2022-08-10T00:08:25.480937Z",
          "shell.execute_reply.started": "2022-08-10T00:08:25.470511Z",
          "shell.execute_reply": "2022-08-10T00:08:25.47937Z"
        },
        "trusted": true,
        "id": "xp5JhXZpuzwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy= \"epoch\", # Disabled for runtime evaluation\n",
        "    evaluation_strategy=\"steps\", #\"steps\", # Disabled for runtime evaluation\n",
        "    eval_steps = 500,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",\n",
        "    #fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:25.482641Z",
          "iopub.execute_input": "2022-08-10T00:08:25.48332Z",
          "iopub.status.idle": "2022-08-10T00:08:25.499844Z",
          "shell.execute_reply.started": "2022-08-10T00:08:25.483266Z",
          "shell.execute_reply": "2022-08-10T00:08:25.498769Z"
        },
        "trusted": true,
        "id": "leUDiqwuuzwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model\n",
        "\n",
        "GPU used by Kaggle: https://www.nvidia.com/de-de/data-center/tesla-p100/"
      ],
      "metadata": {
        "id": "uiMhuzSOuzwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:25.501545Z",
          "iopub.execute_input": "2022-08-10T00:08:25.501937Z",
          "iopub.status.idle": "2022-08-10T00:08:26.741054Z",
          "shell.execute_reply.started": "2022-08-10T00:08:25.5019Z",
          "shell.execute_reply": "2022-08-10T00:08:26.739749Z"
        },
        "trusted": true,
        "id": "U7ul-kF4uzwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:08:26.742889Z",
          "iopub.execute_input": "2022-08-10T00:08:26.744077Z",
          "iopub.status.idle": "2022-08-10T00:18:26.270935Z",
          "shell.execute_reply.started": "2022-08-10T00:08:26.744035Z",
          "shell.execute_reply": "2022-08-10T00:18:26.269854Z"
        },
        "trusted": true,
        "id": "pC-xHDAPuzwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\"Eval Loss: {eval_results['eval_loss']}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:18:26.272378Z",
          "iopub.execute_input": "2022-08-10T00:18:26.274755Z",
          "iopub.status.idle": "2022-08-10T00:19:06.404391Z",
          "shell.execute_reply.started": "2022-08-10T00:18:26.274684Z",
          "shell.execute_reply": "2022-08-10T00:19:06.40328Z"
        },
        "trusted": true,
        "id": "VaXyizZTuzwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Model Finetuned Model:"
      ],
      "metadata": {
        "id": "Thjt8nkfuzwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load checkpoint:"
      ],
      "metadata": {
        "id": "MBhm4L7SuzwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tuned = BloomForTokenClassification.from_pretrained(\"./results/checkpoint-1171\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:20:15.174592Z",
          "iopub.execute_input": "2022-08-10T00:20:15.174987Z",
          "iopub.status.idle": "2022-08-10T00:20:32.608546Z",
          "shell.execute_reply.started": "2022-08-10T00:20:15.174954Z",
          "shell.execute_reply": "2022-08-10T00:20:32.607584Z"
        },
        "trusted": true,
        "id": "CmgF44S2uzwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set correct class labels:"
      ],
      "metadata": {
        "id": "UN43WxDUuzwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
        "\n",
        "id2label = {id : label for id, label in enumerate(label_names)}\n",
        "label2id = {label: id for id, label in enumerate(label_names)}\n",
        "\n",
        "model_tuned.config.id2label = id2label\n",
        "model_tuned.config.label2id = label2id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:20:35.555823Z",
          "iopub.execute_input": "2022-08-10T00:20:35.556196Z",
          "iopub.status.idle": "2022-08-10T00:20:35.563163Z",
          "shell.execute_reply.started": "2022-08-10T00:20:35.556162Z",
          "shell.execute_reply": "2022-08-10T00:20:35.561883Z"
        },
        "trusted": true,
        "id": "Ne0fcIhRuzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tuned.config.id2label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:20:36.849995Z",
          "iopub.execute_input": "2022-08-10T00:20:36.850399Z",
          "iopub.status.idle": "2022-08-10T00:20:36.857525Z",
          "shell.execute_reply.started": "2022-08-10T00:20:36.850366Z",
          "shell.execute_reply": "2022-08-10T00:20:36.856248Z"
        },
        "trusted": true,
        "id": "DDL1CmwsuzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    \"HuggingFace is a company based in Paris and New York\",\n",
        "    add_special_tokens=False, return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model_tuned(**inputs).logits\n",
        "\n",
        "predicted_token_class_ids = logits.argmax(-1)\n",
        "\n",
        "# Note that tokens are classified rather then input words which means that\n",
        "# there might be more predicted token classes than words.\n",
        "# Multiple token classes might account for the same word\n",
        "predicted_tokens_classes = [model_tuned.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
        "predicted_tokens_classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-10T00:20:37.929164Z",
          "iopub.execute_input": "2022-08-10T00:20:37.929856Z",
          "iopub.status.idle": "2022-08-10T00:20:38.384253Z",
          "shell.execute_reply.started": "2022-08-10T00:20:37.929813Z",
          "shell.execute_reply": "2022-08-10T00:20:38.38326Z"
        },
        "trusted": true,
        "id": "7PRJ_oY1uzwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqWS_XTSuzwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}