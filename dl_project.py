# -*- coding: utf-8 -*-
"""Dl Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nNyu7ZC5C0iO_Qn4Fuvea1TcElctFA_R
"""

import tensorflow as tf

from google.colab import files
uploaded = files.upload()

# Define the directory containing your dataset
dataset_dir = "birds_dataset"

# Define parameters for loading the dataset
batch_size = 32
img_size = (224, 224)
seed = 42

# Create the TensorFlow dataset
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,  # 80% for training, 20% for validation
    subset="training",
    seed=seed,
    image_size=img_size,
    batch_size=batch_size,
)

validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="validation",
    seed=seed,
    image_size=img_size,
    batch_size=batch_size,
)

# Print class names
class_names = train_dataset.class_names
print("Class names:", class_names)

"""# Visualize the first batch"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")
plt.show()

"""model"""

from tensorflow.keras import layers

# Define the model
model = tf.keras.Sequential([
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),
    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(324, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(class_names))  # Output layer with number of classes
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
history = model.fit(
    train_dataset,
    validation_data=validation_dataset,
    epochs=10
)

pip install gradio

import gradio as gr

# Function to make predictions
def classify_image(image):
    # Preprocess the image
    img = tf.image.resize(image, (224, 224))
    img = tf.expand_dims(img, 0)  # Add batch dimension
    # Make prediction
    prediction = model.predict(img)
    predicted_class = class_names[prediction.argmax()]
    return predicted_class

# Gradio interface
image_input = gr.inputs.Image(shape=(224, 224))
label_output = gr.outputs.Label()

# Create interface
gr.Interface(classify_image, image_input, label_output,
             title="Bird Species Classification",
             description="Upload an image of a bird to classify its species.").launch()